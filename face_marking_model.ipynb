{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "标题：人脸颜值打分模型\n",
    "\n",
    "作者：Koorye\n",
    "\n",
    "日期：2020-11-14\n",
    "\n",
    "使用数据集：华南理工大学人脸数据集 SCUT-FBP5500\n",
    "\n",
    "使用第三方库：\n",
    "- Tensorflow2.Keras 搭建神经网络模型\n",
    "- Pandas 处理数据\n",
    "- Numpy 科学运算\n",
    "- PIL 图像的简单处理\n",
    "- OS 系统操作 (文件的增删改查)\n",
    "- Shutil 同上\n",
    "- Sklearn 机器学习包"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import os\n",
    "import shutil\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "预处理图像：\n",
    "1. 输入一张图片的路径\n",
    "2. 拉伸成对应尺寸\n",
    "3. 转换成 RGB 三通道的 Numpy 数组 (宽, 高, RGB)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_image_to_array(img_path, img_width, img_height):\n",
    "    \"\"\" 对图像进行预处理，转换成对应宽高的三通道颜色三维数组 \"\"\"\n",
    "    img = PIL.Image.open(img_path)\n",
    "    img = img.resize((img_width, img_height))\n",
    "    return np.array(img.convert('RGB')).reshape((img_width, img_height, 3)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_dir_to_arrays(dir_path, img_width, img_height):\n",
    "    \"\"\" 对图像目录进行批量预处理转换 \"\"\"\n",
    "    files = os.listdir(dir_path)\n",
    "    arrays = []\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):\n",
    "            arrays.append(convert_image_to_array(dir_path+'/' + file, img_width, img_height))\n",
    "    return np.array(arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "以追加模式保存数据为 CSV，不设置表头和目录。\n",
    "\n",
    "用于损失函数数据的保存。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_data_as_csv(data, path, header):\n",
    "    \"\"\" 将 DataFrame 保存为 CSV \"\"\"\n",
    "    if os.path.exists(path):\n",
    "        data.to_csv(path, mode='a', header=None, index=None)\n",
    "    else:\n",
    "        data.to_csv(path, mode='a', header=header, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "模型主体：\n",
    "\n",
    "- 初始化流程：\n",
    "  1. 设定图片宽高 (影响特征的维度)\n",
    "  2. 读取图片目录并转化为样本集 (样本数, 宽, 高, RGB)\n",
    "  3. 读取标签\n",
    "  4. 切割样本集为训练集和测试集\n",
    "  5. 构建神经网络模型 ResNet50 + Dropout + Dense(Sigmoid)\n",
    "  6. 实现模型的保存和读取\n",
    "\n",
    "- 训练流程：\n",
    "  1. 如果不训练新模型 (默认)，就读取旧模型\n",
    "  2. 使用 SGD 作为学习器，均方差作为损失函数\n",
    "  3. 训练并保存模型和损失\n",
    "\n",
    "- 预测流程：\n",
    "  1. 喂入图片，转换成(样本数, 宽, 高, RGB) 的四维矩阵 (其中样本数=1)\n",
    "  2. 使用模型的预测函数进行预测\n",
    "  3. 将预测结果提取出来"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \"\"\" 人脸颜值打分模型，使用 ResNet50 作为基模型 \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" 初始化矩阵尺寸，数据集预处理，划分训练集与测试集，搭建网络模型，实现断点续训 \"\"\"\n",
    "        self.img_width, self.img_height = 100, 120\n",
    "\n",
    "        self.data = convert_dir_to_arrays('data/female-face/allpicture', self.img_width, self.img_height)\n",
    "\n",
    "        self.target = np.array(pd.read_excel('data/female-face/grades.xlsx')['label']) / 5\n",
    "\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = sklearn.model_selection.train_test_split(self.data,\n",
    "                                                                                                        self.target,\n",
    "                                                                                                        test_size=0.3,\n",
    "                                                                                                        random_state=0)\n",
    "\n",
    "        self.model = tf.keras.Sequential([\n",
    "                tf.keras.applications.ResNet50(include_top=False, pooling='avg'),\n",
    "                tf.keras.layers.Dropout(0.5),\n",
    "                tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "        self.base_path = 'model/face_marking_model'\n",
    "        self.checkpoint_save_path = 'checkpoint/mnist.ckpt'\n",
    "\n",
    "        self.cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=self.base_path + '/' + self.checkpoint_save_path,\n",
    "                                                              save_weights_only=True,\n",
    "                                                              save_best_only=True)\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\" 加载模型 \"\"\"\n",
    "        self.model.load_weights(self.base_path + '/' + self.checkpoint_save_path)\n",
    "\n",
    "    def fit(self, epochs, new_model=False):\n",
    "        \"\"\" 训练模型，设定训练次数和是否使用新模型 (使用新模型将删除训练好的模型！) \"\"\"\n",
    "        if new_model:\n",
    "            print('[ WARN ] >>> All record of model will be removed!')\n",
    "            if os.path.exists(self.base_path):\n",
    "                shutil.rmtree(self.base_path)\n",
    "\n",
    "        else:\n",
    "            if os.path.exists(self.base_path + '/' + self.checkpoint_save_path + '.index'):\n",
    "                print('[ INFO ] >>> Model is exist! Loading the model!')\n",
    "                self.model.load_weights(self.base_path + '/' + self.checkpoint_save_path)\n",
    "            else:\n",
    "                print('[ INFO ] >>> Model is not exist! Creating the model!')\n",
    "\n",
    "        self.model.compile(optimizer='sgd',\n",
    "                           loss='mse')\n",
    "\n",
    "        self.model.fit(self.x_train,\n",
    "                       self.y_train,\n",
    "                       batch_size=64,\n",
    "                       epochs=epochs,\n",
    "                       validation_data=(self.x_test, self.y_test),\n",
    "                       validation_freq=1,\n",
    "                       callbacks=[self.cp_callback])\n",
    "\n",
    "        save_data_as_csv(pd.concat([pd.DataFrame(self.model.history.history['loss']),\n",
    "                                    pd.DataFrame(self.model.history.history['val_loss'])],\n",
    "                                    axis=1),\n",
    "                 path=self.base_path + '/' + 'loss.csv',\n",
    "                 header=['loss', 'val_loss'])\n",
    "\n",
    "    def predict(self, img_path):\n",
    "        \"\"\" 预测分数，输入一张图片的路径 \"\"\"\n",
    "        return self.model.predict(convert_image_to_array(img_path, self.img_width, self.img_height).reshape(1, self.img_width, self.img_height, 3)).flatten()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-50-be507aaf4daa>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mModel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-49-7ab814cf3546>\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m      5\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimg_width\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimg_height\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m100\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m120\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconvert_dir_to_arrays\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'data/female-face/allpicture'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimg_width\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimg_height\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtarget\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_excel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'data/female-face/grades.xlsx'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'label'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;36m5\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-47-31a828aad731>\u001B[0m in \u001B[0;36mconvert_dir_to_arrays\u001B[1;34m(dir_path, img_width, img_height)\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mfile\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mfiles\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mendswith\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'.jpg'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m             \u001B[0marrays\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconvert_image_to_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdir_path\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m'/'\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimg_width\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimg_height\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marrays\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-46-284aa70ea535>\u001B[0m in \u001B[0;36mconvert_image_to_array\u001B[1;34m(img_path, img_width, img_height)\u001B[0m\n\u001B[0;32m      2\u001B[0m     \u001B[1;34m\"\"\" 对图像进行预处理，转换成对应宽高的三通道颜色三维数组 \"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mPIL\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mImage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m     \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg_width\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimg_height\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconvert\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'RGB'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg_width\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimg_height\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'float32'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\environment\\Python3.8.5\\lib\\site-packages\\PIL\\Image.py\u001B[0m in \u001B[0;36mresize\u001B[1;34m(self, size, resample, box, reducing_gap)\u001B[0m\n\u001B[0;32m   1901\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconvert\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1902\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1903\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1904\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1905\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mreducing_gap\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mresample\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mNEAREST\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\environment\\Python3.8.5\\lib\\site-packages\\PIL\\ImageFile.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    263\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    264\u001B[0m                             \u001B[0mb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mb\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 265\u001B[1;33m                             \u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merr_code\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdecoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    266\u001B[0m                             \u001B[1;32mif\u001B[0m \u001B[0mn\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    267\u001B[0m                                 \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(1, new_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.read_csv(model.base_path + '/loss.csv').plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test, y_predict = model.y_test, model.model.predict(model.x_test)\n",
    "\n",
    "# zipped = sorted(zip(y_test, y_predict))\n",
    "# y_test, y_predict = [], []\n",
    "# for each in zipped:\n",
    "#     y_test.append(each[0])\n",
    "#     y_predict.append(each[1])\n",
    "\n",
    "plt.scatter(range(len(y_test)), y_test, label='y_test', alpha=0.7)\n",
    "plt.scatter(range(len(y_test)), y_predict, label='y_predict', alpha=0.7)\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.predict('a2f607824ce2ae7feeac3ec5d1542280.jpg') * 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.predict('900ba11a29acd697088fab14eddfb8db.jpg') * 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (machine-learning)",
   "language": "python",
   "name": "pycharm-7c4dd109"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}